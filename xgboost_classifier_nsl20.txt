
                                             XGBOOST CLASSIFIER NSL20
-----------------------------------------------------------------------------------------------------------------------

import xgboost as xgb

----------------------------------------------------------

import numpy as np
import pandas as pd

---------------------------------------------------------

df=pd.read_csv(r"C:\Users\dell\OneDrive\Desktop\nsl_20_percent latest(1).txt",)

------------------------------------------------------------------------------------

input : df.head

output-
0 	0.1 	0.2 	0.3 	0.4 	0.5 	0.6 	0.7 	0.8 	0.9 	... 	11 	0.04 	0.07.1 	0.20 	0.21 	1.2 	1.3 	0.22 	0.23 	dos
0 	tcp 	private 	REJ 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	... 	1 	0.00 	0.84 	0.00 	0.00 	0.07 	0.0 	0.62 	1.0 	probe
udp 	domain_u 	SF 	42 	42 	0 	0 	0 	0 	0 	0 	0 	0 	0 	... 	83 	0.99 	0.02 	0.01 	0.00 	0.00 	0.0 	0.00 	0.0 	normal
tcp 	ftp_data 	SF 	12 	0 	0 	0 	0 	0 	0 	1 	0 	0 	0 	... 	47 	0.55 	0.07 	0.55 	0.04 	0.00 	0.0 	0.00 	0.0 	normal
domain 	S0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	... 	2 	0.01 	0.07 	0.00 	0.00 	1.00 	1.0 	0.00 	0.0 	dos
http 	SF 	353 	1483 	0 	0 	0 	0 	0 	1 	0 	0 	0 	... 	255 	1.00 	0.00 	0.00 	0.00 	0.00 	0.0 	0.00 	0.0 	normal

---------------------------------------------------------------------------------------------------------------------------------------------


columns = df.columns




-------------------------------------------------------


len(df[columns[0]].unique())


-------------------------------------------------------

d = dict()
for i in columns:
    d[i]=len(df[i].unique())





------------------------------------------------------

input: d

output: 
{'0': 3921,
 '0.1': 2,
 '0.2': 3,
 '0.3': 1,
 '0.4': 20,
 '0.5': 6,
 '0.6': 2,
 '0.7': 27,
 '0.8': 2,
 '0.9': 3,
 '0.10': 25,
 '0.11': 17,
 '0.12': 3,
 '0.13': 9,
 '0.14': 1,
 '0.15': 1,
 '0.16': 2,
 '135': 465,
 '9': 416,
 '1': 72,
 '1.1': 52,
 '0.17': 69,
 '0.18': 47,
 '0.07': 97,
 '0.06': 75,
 '0.19': 54,
 '255': 256,
 '11': 256,
 '0.04': 101,
 '0.07.1': 101,
 '0.20': 101,
 '0.21': 64,
 '1.2': 99,
 '1.3': 87,
 '0.22': 101,
 '0.23': 97,
 'dos': 5}

-----------------------------------------------------------------------------------------

df_to_train = df.iloc[:,:-1]


---------------------------------------------------------------------------

input: df_to_train.head()

output:
0 	0.1 	0.2 	0.3 	0.4 	0.5 	0.6 	0.7 	0.8 	0.9 	... 	255 	11 	0.04 	0.07.1 	0.20 	0.21 	1.2 	1.3 	0.22 	0.23
0 	tcp 	private 	REJ 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	... 	255 	1 	0.00 	0.84 	0.00 	0.00 	0.07 	0.0 	0.62 	1.0
udp 	domain_u 	SF 	42 	42 	0 	0 	0 	0 	0 	0 	0 	0 	0 	... 	84 	83 	0.99 	0.02 	0.01 	0.00 	0.00 	0.0 	0.00 	0.0
tcp 	ftp_data 	SF 	12 	0 	0 	0 	0 	0 	0 	1 	0 	0 	0 	... 	44 	47 	0.55 	0.07 	0.55 	0.04 	0.00 	0.0 	0.00 	0.0
domain 	S0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	... 	255 	2 	0.01 	0.07 	0.00 	0.00 	1.00 	1.0 	0.00 	0.0
http 	SF 	353 	1483 	0 	0 	0 	0 	0 	1 	0 	0 	0 	... 	255 	255 	1.00 	0.00 	0.00 	0.00 	0.00 	0.0 	0.00 	0.0

5 rows × 36 columns

--------------------------------------------------------------------------------------------------------------------------------------------


df_to_test = df.iloc[:,-1]

---------------------------------------------------------------------------------------

input: df_to_test.head()

output:
0  tcp  private   REJ  0       probe
   udp  domain_u  SF   42     normal
   tcp  ftp_data  SF   12     normal
        domain    S0   0         dos
        http      SF   353    normal
Name: dos, dtype: object

----------------------------------------------------------------------------------------------

from sklearn.preprocessing import LabelEncoder
number = LabelEncoder()

---------------------------------------------------------------------------------------------

number = LabelEncoder()
df_to_test = number.fit_transform(df_to_test.astype('str'))

------------------------------------------------------------------------------------------------

input: df_to_test

output:
array([2, 1, 1, ..., 0, 1, 1])

------------------------------------------------------------------------------

input: df_to_train.dtypes

output:
0           int64
0.1         int64
0.2         int64
0.3         int64
0.4         int64
0.5         int64
0.6         int64
0.7         int64
0.8         int64
0.9         int64
0.10        int64
0.11        int64
0.12        int64
0.13        int64
0.14        int64
0.15        int64
0.16        int64
135         int64
9           int64
1         float64
1.1       float64
0.17      float64
0.18      float64
0.07      float64
0.06      float64
0.19      float64
255         int64
11          int64
0.04      float64
0.07.1    float64
0.20      float64
0.21      float64
1.2       float64
1.3       float64
0.22      float64
0.23      float64
dtype: object

----------------------------------------------------------

from sklearn import model_selection
from sklearn.model_selection import train_test_split

-------------------------------------------------------

df_to_train_train,df_to_train_test,df_to_test_train,df_to_test_test = train_test_split(df_to_train,df_to_test,test_size = 0.2)


-------------------------------------------------------------------------------------------------------------------------------

input: df_to_train_train.shape

output:
(20124, 36)

-----------------------------------------------------------------------------------

intput: df_to_train_test.shape

output:
(5032, 36)


---------------------------------------------------------------------------

intput: df_to_test_train.shape

output:
(20124,)

-----------------------------------------------------------------------------

from xgboost import XGBClassifier


----------------------------------------------------------------------------

intput: model = XGBClassifier()
model.fit(df_to_train_train,df_to_test_train)


output:
XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,
       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,
       n_estimators=100, n_jobs=1, nthread=None,
       objective='multi:softprob', random_state=0, reg_alpha=0,
       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,
       subsample=1, verbosity=1)

------------------------------------------------------------------------

from sklearn.metrics import accuracy_score

-----------------------------------------------------------------------

intput: print(accuracy_score(df_to_test_test,model.predict(df_to_train_test)))

output:
0.9924483306836248


-------------------------------------------------------------------------

from sklearn.metrics import classification_report
from sklearn import metrics

----------------------------------------------------------------

y_expected = df_to_test_test

---------------------------------------------------------------

y_pred = model.predict(df_to_train_test)

-----------------------------------------------------------------

intput: print(metrics.classification_report(y_expected, y_pred))

output:
precision    recall  f1-score   support

           0       1.00      0.99      1.00      1875
           1       0.99      1.00      0.99      2656
           2       0.99      0.97      0.98       453
           3       0.91      0.91      0.91        47
           4       0.00      0.00      0.00         1

   micro avg       0.99      0.99      0.99      5032
   macro avg       0.78      0.77      0.78      5032
weighted avg       0.99      0.99      0.99      5032

----------------------------------------------------------

from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt

---------------------------------------------------------------

intput: print(metrics.confusion_matrix(y_expected, y_pred))

output:

[[1864   10    1    0    0]
 [   0 2649    3    4    0]
 [   1   14  438    0    0]
 [   1    3    0   43    0]
 [   0    1    0    0    0]]
-------------------------------------------------------------------------

--------------------------------------------------------------